# -*- coding: utf-8 -*-
"""StackOverflow_tags_Bidirectional_LSTM_Glove.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XfH1-5jqEroh991SnM3RitKpcnD0TJib
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x

from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout, Embedding, CuDNNLSTM, Bidirectional
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
from keras.callbacks import ModelCheckpoint
from tensorflow.keras.callbacks import Callback
from tensorflow.keras.callbacks import EarlyStopping
from keras.models import load_model
from sklearn.metrics import roc_auc_score
from tqdm import tqdm
import pandas as pd
import numpy as np
import pickle

flattened = pd.read_pickle("/content/drive/My Drive/Stack_Overflow/flattened.pkl")
flattened.shape

data = flattened[0:150000]

data.head(2)

train,test = train_test_split(data,test_size=0.3)

x_train=train['Title & Body']
y_train=train[['android', 'c#', 'c++', 'html', 'ios', 'java','javascript', 'jquery', 'php', 'python']]
x_test=test['Title & Body']
y_test=test[['android', 'c#', 'c++', 'html', 'ios', 'java','javascript', 'jquery', 'php', 'python']]

#!unzip '/content/drive/My Drive/glove.840B.300d.zip'

token = Tokenizer()
token.fit_on_texts(x_train)
seq = token.texts_to_sequences(x_train)

pad_seq = pad_sequences(seq,maxlen=300)

vocab_size = len(token.word_index)+1

embedding_vector = {}
f = open('/content/glove.840B.300d.txt')
for line in tqdm(f):
    value = line.split(' ')
    word = value[0]
    coef = np.array(value[1:],dtype = 'float32')
    embedding_vector[word] = coef

embedding_matrix = np.zeros((vocab_size,300))
for word,i in tqdm(token.word_index.items()):
    embedding_value = embedding_vector.get(word)
    if embedding_value is not None:
        embedding_matrix[i] = embedding_value

embedding_matrix.shape

del data

del flattened

model = Sequential()
model.add(Embedding(vocab_size,300,weights = [embedding_matrix],input_length=300,trainable = False))
model.add(Bidirectional(CuDNNLSTM(126)))
model.add(Dense(64,activation = 'relu'))
model.add(Dense(128,activation = 'relu'))
model.add(Dropout(0.3))
model.add(Dense(10,activation = 'sigmoid'))
model.compile(optimizer='adam',loss='binary_crossentropy',metrics = ['accuracy'])

outputFolder = '/content/drive/My Drive/Stack_Overflow/'
filepath=outputFolder+"/weights.h5"
checkpoint = ModelCheckpoint(filepath, monitor='val_loss', 
                             verbose=1, 
                             save_best_only=True,
                             save_weights_only=False, 
                             mode='auto')

earlystop = EarlyStopping(monitor='val_loss', 
                          min_delta=0.01, patience=10,
                          verbose=1, mode='auto')

model.fit(pad_seq, y_train,epochs = 50,batch_size=16,validation_split=0.2,callbacks=[earlystop,checkpoint])

data_test = flattened[350000:360000]
data_test.head(1)

model = load_model('/content/drive/My Drive/Stack_Overflow/weights.h5')
token = Tokenizer()
token.fit_on_texts(data_test['Title & Body'])
sequences = token.texts_to_sequences(data_test['Title & Body'])

test_pad_seq = pad_sequences(sequences,maxlen=300)

predictions=model.predict(test_pad_seq)

predictions.round()

roc_auc_score(np.asarray(data_test[['android', 'c#', 'c++', 'html', 'ios', 'java','javascript', 'jquery', 'php', 'python']]),predictions.round())

import numpy as np
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.metrics import roc_auc_score

y_true = np.asarray(data_test[['android', 'c#', 'c++', 'html', 'ios', 'java','javascript', 'jquery', 'php', 'python']])
y_pred = predictions.round()

labels = ['android', 'c#', 'c++', 'html', 'ios', 'java','javascript', 'jquery', 'php', 'python']

conf_mat_dict={}

for label_col in range(len(labels)):
    y_true_label = y_true[:, label_col]
    y_pred_label = y_pred[:, label_col]
    conf_mat_dict[labels[label_col]] = confusion_matrix(y_pred=y_pred_label, y_true=y_true_label)


for label, matrix in conf_mat_dict.items():
    print("Confusion matrix for label {}:".format(label))
    print(matrix)
print(classification_report(y_true,y_pred))
print(roc_auc_score(y_true,y_pred))
print(accuracy_score(y_true,y_pred))

