import pandas as pd

# Assuming you have two dataframes: main_df and analyst_df

# Sample data
main_data = {'Comments': ['Analyst1 mentioned', '16Jan mentioned', 'No analyst here', 'Jan noted', 'No match']}
analyst_data = {'BVname': ['BV1', 'BV2'],
                'CName': ['Analyst1', 'Jan'],
                'SOE': ['SOE1', 'SOE2']}

main_df = pd.DataFrame(main_data)
analyst_df = pd.DataFrame(analyst_data)

# Function to find unique SOE for each comment
def find_soe(comment):
    analyst_names = analyst_df['CName'].values
    found_analysts = [analyst for analyst in analyst_names if f" {analyst} " in f" {comment} "]

    unique_soe_values = set()
    for analyst in found_analysts:
        soe_value = analyst_df.loc[analyst_df['CName'] == analyst, 'SOE'].values
        unique_soe_values.update(soe_value)

    if unique_soe_values:
        return ', '.join(unique_soe_values)
    else:
        return 'No Match'

# Apply the function to create the new 'SOE' column in main_df
main_df['SOE'] = main_df['Comments'].apply(find_soe)

# Print the updated main_df
print(main_df)


import os
import pandas as pd
from tqdm import tqdm
import logging

# Configure logging
logging.basicConfig(filename='consolidation_log.txt', level=logging.INFO)

def consolidate_excel_files(root_folder):
    try:
        # Load or initialize progress data
        progress_file = 'progress.txt'
        current_progress = load_progress(progress_file)

        broker_folders = [f for f in os.listdir(root_folder) if os.path.isdir(os.path.join(root_folder, f))]
        total_brokers = len(broker_folders)

        for i, broker_folder in enumerate(tqdm(broker_folders, desc="Brokers", unit="broker", initial=current_progress['broker_index'])):
            broker_path = os.path.join(root_folder, broker_folder)
            current_progress['broker_index'] = i
            consolidate_files(broker_path, current_progress)

            # Save progress after every 10% completion
            if (i + 1) % (total_brokers // 10) == 0:
                save_progress(progress_file, current_progress)
                logging.info(f"Saved progress after processing {i + 1}/{total_brokers} brokers.")

        logging.info("Consolidation completed successfully.")

    except Exception as e:
        logging.error(f"An error occurred: {e}")
        print(f"An error occurred: {e}")

def consolidate_files(broker_path, current_progress):
    try:
        region_folders = [f for f in os.listdir(broker_path) if os.path.isdir(os.path.join(broker_path, f))]
        total_regions = len(region_folders)

        for i, region_folder in enumerate(tqdm(region_folders, desc="Regions", unit="region", leave=False, initial=current_progress['region_index'])):
            region_path = os.path.join(broker_path, region_folder)
            current_progress['region_index'] = i
            for client_folder in os.listdir(region_path):
                client_path = os.path.join(region_path, client_folder)
                if os.path.isdir(client_path):
                    working_folder = os.path.join(client_path, 'working')
                    if os.path.exists(working_folder):
                        files = [f for f in os.listdir(working_folder) if f.endswith('.xlsx')]
                        if files:
                            df_list = [pd.read_excel(os.path.join(working_folder, file)) for file in files]
                            consolidated_df = pd.concat(df_list, ignore_index=True)
                            consolidated_file_path = os.path.join(working_folder, 'consolidated.xlsx')
                            consolidated_df.to_excel(consolidated_file_path, index=False)
                            print(f"Consolidated {len(files)} files in {working_folder}. Saved to {consolidated_file_path}")

                            # Save progress after every 10% completion
                            if (i + 1) % (total_regions // 10) == 0:
                                save_progress(progress_file, current_progress)
                                logging.info(f"Saved progress after processing {i + 1}/{total_regions} regions in {broker_path}.")

                        else:
                            print(f"No Excel files found in {working_folder}")

        current_progress['region_index'] = 0  # Reset region index for the next broker
    except Exception as e:
        logging.error(f"An error occurred: {e}")
        print(f"An error occurred: {e}")

def load_progress(progress_file):
    if os.path.exists(progress_file):
        with open(progress_file, 'r') as file:
            progress_data = eval(file.read())
        return progress_data
    else:
        return {'broker_index': 0, 'region_index': 0}

def save_progress(progress_file, progress_data):
    with open(progress_file, 'w') as file:
        file.write(str(progress_data))

# Specify the root folder containing broker folders
root_folder = '/path/to/broker/folders'

# Run the consolidation
consolidate_excel_files(root_folder)


import os
import pandas as pd
from tqdm import tqdm
import logging

# Configure logging
logging.basicConfig(filename='consolidation_log.txt', level=logging.INFO)

def consolidate_excel_files(root_folder):
    try:
        # Load or initialize progress data
        progress_file = 'progress.txt'
        current_progress = load_progress(progress_file)

        broker_folders = [f for f in os.listdir(root_folder) if os.path.isdir(os.path.join(root_folder, f))]
        total_brokers = len(broker_folders)

        for i, broker_folder in enumerate(tqdm(broker_folders, desc="Brokers", unit="broker", initial=current_progress['broker_index'])):
            broker_path = os.path.join(root_folder, broker_folder)
            current_progress['broker_index'] = i
            consolidate_files(broker_path, current_progress)

            # Save progress after every 10% completion
            if (i + 1) % (total_brokers // 10) == 0:
                save_progress(progress_file, current_progress)
                logging.info(f"Saved progress after processing {i + 1}/{total_brokers} brokers.")

        logging.info("Consolidation completed successfully.")

    except Exception as e:
        logging.error(f"An error occurred: {e}")
        print(f"An error occurred: {e}")

def consolidate_files(broker_path, current_progress):
    try:
        region_folders = [f for f in os.listdir(broker_path) if os.path.isdir(os.path.join(broker_path, f))]
        total_regions = len(region_folders)

        for i, region_folder in enumerate(tqdm(region_folders, desc="Regions", unit="region", leave=False, initial=current_progress['region_index'])):
            region_path = os.path.join(broker_path, region_folder)
            current_progress['region_index'] = i
            for client_folder in os.listdir(region_path):
                client_path = os.path.join(region_path, client_folder)
                if os.path.isdir(client_path):
                    working_folder = os.path.join(client_path, 'working')
                    if os.path.exists(working_folder):
                        files = [f for f in os.listdir(working_folder) if f.endswith('.xlsx')]
                        if files:
                            df_list = []

                            for file in files:
                                file_path = os.path.join(working_folder, file)
                                try:
                                    df = pd.read_excel(file_path)
                                    # Add new columns with the client folder name and region
                                    df['ClientFolder'] = client_folder
                                    df['Region'] = region_folder
                                    df_list.append(df)
                                except pd.errors.ParserError as e:
                                    logging.warning(f"Skipping file {file_path}. Error: {e}")

                            if df_list:
                                validate_columns(df_list)

                                consolidated_df = pd.concat(df_list, ignore_index=True)
                                consolidated_file_path = os.path.join(working_folder, 'consolidated.xlsx')
                                consolidated_df.to_excel(consolidated_file_path, index=False)
                                print(f"Consolidated {len(files)} files in {working_folder}. Saved to {consolidated_file_path}")

                                # Save progress after every 10% completion
                                if (i + 1) % (total_regions // 10) == 0:
                                    save_progress(progress_file, current_progress)
                                    logging.info(f"Saved progress after processing {i + 1}/{total_regions} regions in {broker_path}.")

                            else:
                                print(f"No valid Excel files found in {working_folder}")

        current_progress['region_index'] = 0  # Reset region index for the next broker
    except Exception as e:
        logging.error(f"An error occurred: {e}")
        print(f"An error occurred: {e}")

def load_progress(progress_file):
    if os.path.exists(progress_file):
        with open(progress_file, 'r') as file:
            progress_data = eval(file.read())
        return progress_data
    else:
        return {'broker_index': 0, 'region_index': 0}

def save_progress(progress_file, progress_data):
    with open(progress_file, 'w') as file:
        file.write(str(progress_data))

def validate_columns(df_list):
    # Validate that the number of columns in all DataFrames is the same
    num_columns = len(df_list[0].columns)
    for df in df_list[1:]:
        if len(df.columns) != num_columns:
            logging.warning("Number of columns in Excel files does not match. Skipping file.")
            raise ValueError("Number of columns in Excel files does not match.")

# Specify the root folder containing broker folders
root_folder = '/path/to/broker/folders'

# Run the consolidation
consolidate_excel_files(root_folder)
