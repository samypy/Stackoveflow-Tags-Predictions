
import os
import pandas as pd
from concurrent.futures import ProcessPoolExecutor
from tqdm import tqdm
import logging

# Configure logging
logging.basicConfig(filename='consolidation_log.txt', level=logging.INFO)

def consolidate_excel_files(root_folder):
    try:
        # Load or initialize progress data
        progress_file = 'progress.txt'
        current_progress = load_progress(progress_file)

        region_folders = [f for f in os.listdir(root_folder) if os.path.isdir(os.path.join(root_folder, f))]
        total_regions = len(region_folders)

        with ProcessPoolExecutor() as executor:
            futures = []
            for i, region_folder in enumerate(region_folders[current_progress['region_index']:]):
                region_path = os.path.join(root_folder, region_folder)
                current_progress['region_index'] = i
                futures.append(executor.submit(consolidate_files, region_path, current_progress))

            # Wait for all tasks to complete
            for future in tqdm(futures, desc="Regions", unit="region"):
                try:
                    future.result()
                except Exception as e:
                    logging.error(f"Error in one of the processes: {e}")
                    print(f"Error in one of the processes: {e}")

            # Save the consolidated file on the desktop
            consolidate_on_desktop(root_folder)

            # Save progress after processing all regions
            save_progress(progress_file, current_progress)
            logging.info(f"Saved progress after processing all regions.")

        logging.info("Consolidation completed successfully.")

    except Exception as e:
        logging.error(f"An error occurred: {e}")
        print(f"An error occurred: {e}")

def consolidate_files(region_path, current_progress):
    try:
        client_folders = [f for f in os.listdir(region_path) if os.path.isdir(os.path.join(region_path, f))]
        total_clients = len(client_folders)

        with ProcessPoolExecutor() as executor:
            futures = []
            for i, client_folder in enumerate(client_folders[current_progress['client_index']:]):
                client_path = os.path.join(region_path, client_folder)
                current_progress['client_index'] = i
                working_folder = os.path.join(client_path, 'Working Files')
                
                if os.path.exists(working_folder):
                    files = [f for f in os.listdir(working_folder) if f.endswith('.xlsm')]
                    if files:
                        futures.append(executor.submit(process_client_folder, working_folder, files, client_folder, region_path))

            # Wait for all tasks to complete
            for future in tqdm(futures, desc="Clients", unit="client"):
                try:
                    future.result()
                except Exception as e:
                    logging.error(f"Error in one of the processes: {e}")
                    print(f"Error in one of the processes: {e}")

            # Save the consolidated file after processing each client folder
            consolidate_on_desktop(region_path)

        current_progress['client_index'] = 0  # Reset client index for the next region
    except Exception as e:
        logging.error(f"An error occurred: {e}")
        print(f"An error occurred: {e}")

def process_client_folder(working_folder, files, client_folder, region_path):
    try:
        df_list = []

        for file in files:
            file_path = os.path.join(working_folder, file)
            try:
                df = pd.read_excel(file_path, engine='openpyxl', usecols='A:Z')  # Include only columns A to Z
                # Add new columns with the client folder name, region, and client
                df['ClientFolder'] = client_folder
                df['Region'] = os.path.basename(region_path)
                df_list.append(df)
            except pd.errors.ParserError as e:
                logging.warning(f"Skipping file {file_path}. Error: {e}")

        if df_list:
            validate_columns(df_list)

            consolidated_df = pd.concat(df_list, ignore_index=True)
            # Save the consolidated DataFrame to the desktop
            desktop_path = os.path.join(os.path.expanduser("~"), 'Desktop')
            consolidated_file_path = os.path.join(desktop_path, 'consolidated_partial.xlsx')
            consolidated_df.to_excel(consolidated_file_path, index=False, engine='openpyxl')
            print(f"Consolidated {len(df_list)} files in {working_folder}. Saved to {consolidated_file_path}")

        else:
            print(f"No valid Excel files found in {working_folder}")

    except Exception as e:
        logging.error(f"An error occurred: {e}")
        print(f"An error occurred: {e}")

def consolidate_on_desktop(folder_path):
    try:
        df_list = []

        working_folder = os.path.join(folder_path, 'Working Files')

        if os.path.exists(working_folder):
            files = [f for f in os.listdir(working_folder) if f.endswith('.xlsm')]
            if files:
                for file in files:
                    file_path = os.path.join(working_folder, file)
                    try:
                        df = pd.read_excel(file_path, engine='openpyxl', usecols='A:Z')  # Include only columns A to Z
                        # Add new columns with the client folder name, region, and client
                        df['ClientFolder'] = os.path.basename(folder_path)
                        df['Region'] = os.path.basename(os.path.dirname(folder_path))
                        df_list.append(df)
                    except pd.errors.ParserError as e:
                        logging.warning(f"Skipping file {file_path}. Error: {e}")

        if df_list:
            validate_columns(df_list)

            consolidated_df = pd.concat(df_list, ignore_index=True)
            # Save the consolidated DataFrame to the desktop
            desktop_path = os.path.join(os.path.expanduser("~"), 'Desktop')
            consolidated_file_path = os.path.join(desktop_path, 'consolidated_partial.xlsx')
            consolidated_df.to_excel(consolidated_file_path, index=False, engine='openpyxl')
            print(f"Consolidated {len(df_list)} files in {folder_path}. Saved to {consolidated_file_path}")

        else:
            print(f"No valid Excel files found in {working_folder}")

    except Exception as e:
        logging.error(f"An error occurred: {e}")
        print(f"An error occurred: {e}")

def load_progress(progress_file):
    if os.path.exists(progress_file):
        with open(progress_file, 'r') as file:
            progress_data = eval(file.read())
        return progress_data
    else:
        return {'region_index': 0, 'client_index': 0}

def save_progress(progress_file, progress_data):
    with open(progress_file, 'w') as file:
        file.write(str(progress_data))

def validate_columns(df_list):
    # Validate that the number of columns in all DataFrames is the same
    num_columns = len(df_list[0].columns)
    for df in df_list[1:]:
        if len

import os
import pandas as pd
from concurrent.futures import ProcessPoolExecutor
from tqdm import tqdm
import logging

# Configure logging
logging.basicConfig(filename='consolidation_log.txt', level=logging.INFO)

def consolidate_excel_files(root_folder):
    try:
        # Load or initialize progress data
        progress_file = 'progress.txt'
        current_progress = load_progress(progress_file)

        region_folders = [f for f in os.listdir(root_folder) if os.path.isdir(os.path.join(root_folder, f))]
        total_regions = len(region_folders)

        with ProcessPoolExecutor() as executor:
            futures = []
            for i, region_folder in enumerate(region_folders[current_progress['region_index']:]):
                region_path = os.path.join(root_folder, region_folder)
                current_progress['region_index'] = i
                futures.append(executor.submit(consolidate_files, region_path, current_progress))

            # Wait for all tasks to complete
            for future in tqdm(futures, desc="Regions", unit="region"):
                try:
                    future.result()
                except Exception as e:
                    logging.error(f"Error in one of the processes: {e}")
                    print(f"Error in one of the processes: {e}")

            # Save the consolidated file on the desktop
            consolidate_on_desktop(root_folder)

            # Save progress after processing all regions
            save_progress(progress_file, current_progress)
            logging.info(f"Saved progress after processing all regions.")

        logging.info("Consolidation completed successfully.")

    except Exception as e:
        logging.error(f"An error occurred: {e}")
        print(f"An error occurred: {e}")

def consolidate_files(region_path, current_progress):
    try:
        client_folders = [f for f in os.listdir(region_path) if os.path.isdir(os.path.join(region_path, f))]
        total_clients = len(client_folders)

        with ProcessPoolExecutor() as executor:
            futures = []
            for i, client_folder in enumerate(client_folders[current_progress['client_index']:]):
                client_path = os.path.join(region_path, client_folder)
                current_progress['client_index'] = i
                working_folder = os.path.join(client_path, 'Working Files')
                
                if os.path.exists(working_folder):
                    files = [f for f in os.listdir(working_folder) if f.endswith('.xlsm')]
                    if files:
                        futures.append(executor.submit(process_client_folder, working_folder, files, client_folder, region_path))

            # Wait for all tasks to complete
            for future in tqdm(futures, desc="Clients", unit="client"):
                try:
                    future.result()
                except Exception as e:
                    logging.error(f"Error in one of the processes: {e}")
                    print(f"Error in one of the processes: {e}")

            # Save the consolidated file after processing each client folder
            consolidate_on_desktop(region_path)

        current_progress['client_index'] = 0  # Reset client index for the next region
    except Exception as e:
        logging.error(f"An error occurred: {e}")
        print(f"An error occurred: {e}")

def process_client_folder(working_folder, files, client_folder, region_path):
    try:
        df_list = []

        for file in files:
            file_path = os.path.join(working_folder, file)
            try:
                df = pd.read_excel(file_path, engine='openpyxl', usecols='A:Z')  # Include only columns A to Z
                # Add new columns with the client folder name, region, and client
                df['ClientFolder'] = client_folder
                df['Region'] = os.path.basename(region_path)
                df_list.append(df)
            except pd.errors.ParserError as e:
                logging.warning(f"Skipping file {file_path}. Error: {e}")

        if df_list:
            validate_columns(df_list)

            consolidated_df = pd.concat(df_list, ignore_index=True)
            # Save the consolidated DataFrame to the desktop
            desktop_path = os.path.join(os.path.expanduser("~"), 'Desktop')
            consolidated_file_path = os.path.join(desktop_path, 'consolidated_partial.xlsx')
            consolidated_df.to_excel(consolidated_file_path, index=False, engine='openpyxl')
            print(f"Consolidated {len(df_list)} files in {working_folder}. Saved to {consolidated_file_path}")

        else:
            print(f"No valid Excel files found in {working_folder}")

    except Exception as e:
        logging.error(f"An error occurred: {e}")
        print(f"An error occurred: {e}")

def consolidate_on_desktop(folder_path):
    try:
        df_list = []

        working_folder = os.path.join(folder_path, 'Working Files')

        if os.path.exists(working_folder):
            files = [f for f in os.listdir(working_folder) if f.endswith('.xlsm')]
            if files:
                for file in files:
                    file_path = os.path.join(working_folder, file)
                    try:
                        df = pd.read_excel(file_path, engine='openpyxl', usecols='A:Z')  # Include only columns A to Z
                        # Add new columns with the client folder name, region, and client
                        df['ClientFolder'] = os.path.basename(folder_path)
                        df['Region'] = os.path.basename(os.path.dirname(folder_path))
                        df_list.append(df)
                    except pd.errors.ParserError as e:
                        logging.warning(f"Skipping file {file_path}. Error: {e}")

        if df_list:
            validate_columns(df_list)

            consolidated_df = pd.concat(df_list, ignore_index=True)
            # Save the consolidated DataFrame to the desktop
            desktop_path = os.path.join(os.path.expanduser("~"), 'Desktop')
            consolidated_file_path = os.path.join(desktop_path, 'consolidated_partial.xlsx')
            consolidated_df.to_excel(consolidated_file_path, index=False, engine='openpyxl')
            print(f"Consolidated {len(df_list)} files in {folder_path}. Saved to {consolidated_file_path}")

        else:
            print(f"No valid Excel files found in {working_folder}")

    except Exception as e:
        logging.error(f"An error occurred: {e}")
        print(f"An error occurred: {e}")

def load_progress(progress_file):
    if os.path.exists(progress_file):
        with open(progress_file, 'r') as file:
            progress_data = eval(file.read())
        return progress_data
    else:
        return {'region_index': 0, 'client_index': 0}

def save_progress(progress_file, progress_data):
    with open(progress_file, 'w') as file:
        file.write(str(progress_data))

def validate_columns(df_list):
    # Validate that the number of columns in all DataFrames is the same
    num_columns = len(df_list[0].columns)
    for df in df_list[1:]:
        if len(df.columns) != num_columns:
            logging.warning("Number of columns in Excel files does not match. Skipping file.")
            raise ValueError("Number of columns in Excel files does not match.")

# Specify the root folder containing region folders
root_folder = '/path/to/BV Documents'

# Run the consolidation
consolidate_excel_files(root_folder)
